{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Entendimento do Negócio\n",
        "Trablho em um banco e o principal meio de pagamento utilizado no seu banco é o Pix.\n",
        "\n",
        "Através da base de transações do pix o banco deseja entender qual é o perfil dos clientes que utilizam o pix, além de verificar possíveis transações que tenham fraude. Porém, eles tem um cliente específico que tem um relacionamento muito bom, por isso, recebi base de transações de cliente dos últimos 2 anos e preciso a partir dela criar um relatório contendo as principais características das transações.\n",
        "\n",
        "\n",
        "Então, resumindo, temos dois principais objetivos para esse case:\n",
        "1. Obter valor a partir dos dados\n",
        "  - Para qual banco esse cliente mais transfere?\n",
        "  - Qual é a média de transferências por período que esse cliente faz?\n",
        "  - Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
        "  - Para o que esse cliente mais usa as transferências?\n",
        "2. Executar um algoritmo de machine learning que identifique possíveis transações com fraude.\n",
        "3. Pós Processamento\n",
        "  - Definir cinco métricas de qualidade para os dados\n",
        "  - Explicar se os dados estão com uma boa qualidade"
      ],
      "metadata": {
        "id": "TbBdde6aGU8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação do Ambiente de Desenvolvimento"
      ],
      "metadata": {
        "id": "rAEc9VzRDOgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD1rHH-O68OC"
      },
      "outputs": [],
      "source": [
        "# Instalar a última versão do PySpark\n",
        "!pip install pyspark #==3.3.1\n",
        "\n",
        "# Instalar o NGROK\n",
        "!wget -qnc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -n -q ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# Autenticar a sessão do SparkUI com NGROK\n",
        "!./ngrok authtoken 2KBeQEmmd1YNlQ86GGKf3KFOkb3_6sQH7JEnvEhDxwn9A7WnT\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!sleep 10\n",
        "!curl -s http://localhost:4040/api/tunnels | grep -Po 'public_url\":\"(?=https)\\K[^\"]*'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nrp8Ai9nE1Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Undesrtanting\n",
        "\n",
        "Primeiramente, devemos entender tudo sobre a fonte dos dados\n",
        "- Como o dado chega até nós?\n",
        "- Qual formato virá?\n",
        "- Aonde o processamento será executado (AWS EMR, Cluster On-Premise)?\n",
        "- De quanto em quanto tempo eu preciso gerar esse relatório (mensal, diário, near-real time)?\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"id_transacao\": inteiro,\n",
        "  \"valor\": texto,\n",
        "  \"remetente\": {\n",
        "      \"nome\": texto,\n",
        "      \"banco\": texto,\n",
        "      \"tipo\": texto\n",
        "  },\n",
        "  \"destinatario\": {\n",
        "      \"nome\": texto,\n",
        "      \"banco\":texto,\n",
        "      \"tipo\": texto\n",
        "  },\n",
        "  \"categoria\": texto,\n",
        "  \"transaction_date\":texto,\n",
        "  \"chave_pix\":texto,\n",
        "  \"fraude\":inteiro,\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7Roz2nWxDZs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação dos Dados\n"
      ],
      "metadata": {
        "id": "6aVNWh5RGQFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar a sessão spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "      .config('spark.ui.port', '4050')\n",
        "      .appName(\"CaseFinal\")\n",
        "      .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "QO7yjSxtIMP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "caminho_json = '/content/case_final.json'\n",
        "\n",
        "schema_remetente_destinatario = StructType([\n",
        "    StructField('nome', StringType()),\n",
        "    StructField('banco', StringType()),\n",
        "    StructField('tipo', StringType())\n",
        "])\n",
        "\n",
        "\n",
        "schema_base_pix = StructType([\n",
        "    StructField('id_transacao', IntegerType()),\n",
        "    StructField('valor', DoubleType()),\n",
        "    StructField('remetente', schema_remetente_destinatario),\n",
        "    StructField('destinatario', schema_remetente_destinatario),\n",
        "    StructField('chave_pix', StringType()),\n",
        "    StructField('categoria', StringType()),\n",
        "    StructField('transaction_date', StringType()),\n",
        "    StructField('fraude', IntegerType())\n",
        "])\n",
        "\n",
        "\n",
        "# 2022-10-20 10:57:36\n",
        "\n",
        "df = spark.read.json(\n",
        "    caminho_json,\n",
        "    schema=schema_base_pix,\n",
        "    timestampFormat=\"yyyy-MM-dd HH:mm:ss\",\n",
        ")"
      ],
      "metadata": {
        "id": "-VxCaWbfIVWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "QljyweodJDrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "PMM39M4PJa7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_flatten = df.withColumns({\n",
        "    'remetente_nome':  col('remetente').getField('nome'),\n",
        "    'remetente_banco':  col('remetente').getField('banco'),\n",
        "    'remetente_tipo':  col('remetente').getField('tipo'),\n",
        "    'destinatario_nome':  col('destinatario').getField('nome'),\n",
        "    'destinatario_banco':  col('destinatario').getField('banco'),\n",
        "    'destinatario_tipo':  col('destinatario').getField('tipo'),\n",
        "}).drop('remetente', 'destinatario')"
      ],
      "metadata": {
        "id": "78lpmOegJxo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_flatten.printSchema()\n",
        "\n",
        "df_flatten.show()"
      ],
      "metadata": {
        "id": "EPzNt-vYJ0Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_flatten.describe().show()"
      ],
      "metadata": {
        "id": "wpzsaAbPKC6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem\n",
        "Aqui você encontrará utilidade para os dados levantados.\n",
        "\n",
        "Aqui será onde teremos insights e, a partir desses, novos conhecimentos sobre o business (se tudo até aqui foi feito corretamente).\n",
        "\n",
        "\n",
        "- Para qual banco esse cliente mais transfere?\n",
        "- Qual é a média de transferências por período que esse cliente faz?\n",
        "- Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
        "- Para o que esse cliente mais usa as transferências?\n",
        "- Executar um algoritmo de machine learning que identifique possíveis transações com fraude.\n"
      ],
      "metadata": {
        "id": "HYxf2-n3MVUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para Qual Banco Mais Transfere\n",
        "df_flatten.groupBy('destinatario_banco').count().orderBy('count').show()"
      ],
      "metadata": {
        "id": "l6ijFe5bKC3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Qual Banco mais usa no Mês\n",
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "df_flatten.groupBy(\n",
        "    date_format(col('transaction_date'), 'yyyy-MM').alias('ano_mes'),\n",
        "    'destinatario_banco'\n",
        ").count().orderBy(col('ano_mes').desc()).show()"
      ],
      "metadata": {
        "id": "9QvuSTpdMnyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valor medio das transações\n",
        "df_flatten.groupBy(\n",
        "    'destinatario_banco'\n",
        ").avg('valor').orderBy('avg(valor)').show()"
      ],
      "metadata": {
        "id": "1jJd-u-BMsEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categoria das Despesas\n",
        "df_flatten.groupBy(\n",
        "    date_format(col('transaction_date'), 'yyyy-MM').alias('ano_mes'),\n",
        "    'destinatario_banco',\n",
        "    'categoria'\n",
        ").count().orderBy('ano_mes').show()"
      ],
      "metadata": {
        "id": "reM0vzH7NGk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# soma de quanto ele gasta em cada categoria por mês\n",
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "df_flatten.groupBy(\n",
        "    date_format(col('transaction_date'), 'yyyy').alias('ano'),\n",
        "    'categoria'\n",
        ").sum('valor').select('ano', 'categoria', col('sum(valor)').cast(DecimalType(38, 3)).alias('valor')).orderBy('valor').show(30)"
      ],
      "metadata": {
        "id": "H2vS1MheNJUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# média de transferencia por período\n",
        "\n",
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "df_flatten.groupBy(\n",
        "    date_format(col('transaction_date'), 'yyyy').alias('ano')\n",
        ").avg('id_transacao').select('ano',col('avg(id_transacao)').alias('avg')).orderBy('ano').show(30)"
      ],
      "metadata": {
        "id": "3cKHvASDNZCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantidade de trasanções com fraude\n",
        "df_flatten.groupBy('fraude').count().show()\n"
      ],
      "metadata": {
        "id": "jc2R6wuBNbbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Qual categoria das trasanções com fraude\n",
        "df_flatten.groupBy('categoria', 'fraude').count().show()"
      ],
      "metadata": {
        "id": "9n37O-OyNmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtro de Transferencias com fraude\n",
        "df_flatten.filter(\n",
        "    col('categoria') == 'transferencia'\n",
        ").groupBy('categoria', 'fraude').count().show()"
      ],
      "metadata": {
        "id": "rdK8XkQ8NpMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coluna Range para indetificar numero de Tranferencias com Fraude por valor\n",
        "from pyspark.sql.functions import floor\n",
        "\n",
        "df_flatten.filter(col('fraude') == 1).withColumn(\n",
        "    \"range\",\n",
        "    floor(col(\"valor\")/1000)*1000\n",
        ").groupBy('range').count().orderBy(col('range').desc()).show()"
      ],
      "metadata": {
        "id": "owwC96QgN1Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coluna Range para indetificar numero de Tranferencias com Fraude por valor maximo e minimo\n",
        "from pyspark.sql.functions import floor, max, min\n",
        "\n",
        "df_flatten.filter(\n",
        "    col('fraude') == 1\n",
        ").withColumn(\n",
        "    \"range\", floor(col(\"valor\")/1000)*1000\n",
        ").select(max('range'), min('range')).show()"
      ],
      "metadata": {
        "id": "-n61kP3PN9FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de Predição de Fraudes"
      ],
      "metadata": {
        "id": "oPK6x-vNQ6dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar Bibliotecas necessarias\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "SYn3_7V4Q8Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluir colunas disnecessarias\n",
        "df = df_flatten.drop('remetente', 'id')"
      ],
      "metadata": {
        "id": "rzk3DYC_RCwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar Indexer\n",
        "indexer = StringIndexer(\n",
        "    inputCols=[\n",
        "        \"destinatario_nome\",\n",
        "        \"destinatario_banco\",\n",
        "        \"destinatario_tipo\",\n",
        "        \"categoria\",\n",
        "        \"chave_pix\"\n",
        "    ],\n",
        "    outputCols=[\n",
        "        \"destinatario_nome_index\",\n",
        "        \"destinatario_banco_index\",\n",
        "        \"destinatario_tipo_index\",\n",
        "        \"categoria_index\",\n",
        "        \"chave_pix_index\"\n",
        "    ])"
      ],
      "metadata": {
        "id": "DvcAC-fkR8Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tranformar Dataframe apartir do index\n",
        "df_index = indexer.fit(df).transform(df)\n",
        "df_index.show()"
      ],
      "metadata": {
        "id": "_VKqv_19SOn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar Colunas\n",
        "cols_para_filtrar = [\n",
        "  \"valor\",\n",
        "  \"transaction_date\",\n",
        "  \"destinatario_nome_index\",\n",
        "  \"destinatario_banco_index\",\n",
        "  \"destinatario_tipo_index\",\n",
        "  \"chave_pix_index\",\n",
        "  \"categoria_index\",\n",
        "  \"fraude\"\n",
        "]"
      ],
      "metadata": {
        "id": "1drRFRalSZKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separ Dataframes com e sem Fraude\n",
        "is_fraud = df_index.select(cols_para_filtrar).filter(\"fraude == 1\")\n",
        "no_fraud = df_index.select(cols_para_filtrar).filter(\"fraude == 0\")\n",
        "\n",
        "\n",
        "no_fraud = no_fraud.sample(False, 0.01, seed = 123)"
      ],
      "metadata": {
        "id": "RMHP7B-vS80J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectar dataframes\n",
        "df_concat = no_fraud.union(is_fraud)\n",
        "df = df_concat.sort(\"transaction_date\")\n",
        "df.count()"
      ],
      "metadata": {
        "id": "mDe4XXcOTPfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe de Treino e teste\n",
        "train, test = df.randomSplit([0.7, 0.3], seed = 123)\n",
        "print(\"train =\", train.count(), \" test =\", test.count())"
      ],
      "metadata": {
        "id": "Hy2ziSkYTicZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar função UDF\n",
        "is_fraud = udf(lambda fraud: 1.0 if fraud > 0 else 0.0, DoubleType())\n",
        "train = train.withColumn(\"is_fraud\", is_fraud(train.fraude))"
      ],
      "metadata": {
        "id": "V2U_sqGoUhRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie os vetores de características.\n",
        "# VectorAssembler é um transformador que combina uma dada lista de colunas em uma única coluna de vetor.\n",
        "assembler = VectorAssembler(\n",
        "  inputCols = [x for x in train.columns if x not in [\"transaction_date\", \"fraude\", \"is_fraud\"]],\n",
        "  outputCol = \"features\")\n",
        "\n",
        "# Use Regressão Logística.\n",
        "# é um algoritmo de aprendizado de máquina que é usado para tarefas de classificação.\n",
        "lr = LogisticRegression().setParams(\n",
        "    maxIter = 100000,\n",
        "    labelCol = \"is_fraud\",\n",
        "    predictionCol = \"prediction\")\n",
        "\n",
        "\n",
        "# Isto irá treinar um modelo de regressão logística nos dados de entrada e retornar um\n",
        "# objeto LogisticRegressionModel que pode ser usado para fazer previsões em novos dados.\n",
        "model = Pipeline(stages = [assembler, lr]).fit(train)"
      ],
      "metadata": {
        "id": "RTXLWztAUoTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Predição\n",
        "predicted = model.transform(test)\n",
        "\n",
        "predicted = predicted.withColumn(\"is_fraud\", is_fraud(predicted.fraude))\n",
        "predicted.crosstab(\"is_fraud\", \"prediction\").show()"
      ],
      "metadata": {
        "id": "MX8v5SYIXEWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação do Modelo\n",
        "\n",
        "1.   O modelo identifica corretamente transações acima de R$ 20 mil como fraudulentas?  Sim\n",
        "\n",
        "2.   Ele consegue responder quais são os bancos e categorias mais utilizados? Sim\n",
        "\n",
        "3. A acurácia de 95% atende ao mínimo exigido? Sim"
      ],
      "metadata": {
        "id": "4i7uUF08Ygnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment\n",
        "Apresente o relatório com os resultados obtidos.\n",
        "\n",
        "Foi identificado que o cliente Jonathan Gonsalve tem uma alta taxa de transaferências pix mensal. Através de análise realizadas foi possível perceber que a maior categoria de transação é a transferência bancária.\n",
        "\n",
        "Nota-se que o segundo banco que o cliente mais transaciona é o banco BTG, porém, o mesmo possui o menor valor transacionado, o que indica que o cliente faz muitas transações de menor valor para esse banco.\n",
        "\n",
        "Também foi possível verificar que há um alto índice de tentativas de fraude na conta desse cliente, sendo que todas as tentativas de fraude foram com valores acima de R$19.999,00 e com a categoria de transferência. Por isso, foi criado um algoritimo de machine learning que identifica esses tipos de transações que contém fraude.\n",
        "\n",
        "\n",
        "Conclui-se que há uma alta tentativa de transações com fraude e uma ação possível seria diminuir o limite máximo de transferência de pix do cliente.Possivelmente o cliente esteja usando essa conta PF com propósitos de PJ, devido a alta taxa de transferências s altos valores.  "
      ],
      "metadata": {
        "id": "V2Q5QsI-ZUSS"
      }
    }
  ]
}